{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Bad token\n",
      "\n",
      "\n",
      "ALL DONE \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install bs4 requests\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "\n",
    "# original idea: https://gist.github.com/CharlieTLe/9272de175edb85b07e332c2108288451\n",
    "# see also: https://github.com/GodLesZ/1001tracklists-scraper/blob/master/lib/scraper.js\n",
    "#\n",
    "# to launch: https://mybinder.org/v2/gh/pestrela/music_scripts/master\n",
    "\n",
    "\n",
    "def get_recursive_sets(main_url, limit=5, start=None, grep=None):\n",
    "    urls = get_latest_urls(main_url=main_url, limit=limit, start=start, grep=grep)\n",
    "    \n",
    "    delay = 5\n",
    "    #if limit and (limit > 20):\n",
    "    #    delay = 3\n",
    "        \n",
    "    for url in urls:\n",
    "        get_one_set(url)\n",
    "        time.sleep(delay)\n",
    "\n",
    "        \n",
    "def get_html(url, verbose=True):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\\n%s\\n\" % (url))\n",
    "    return soup        \n",
    "        \n",
    "    \n",
    "def get_latest_urls(main_url, limit=5, start=None, grep=None, verbose=True):\n",
    "    soup = get_html(main_url)\n",
    "\n",
    "    urls = []\n",
    "    \n",
    "    for i, setLink in enumerate(soup.find_all('div', class_=\"tlLink\")):\n",
    "        link = 'https://www.1001tracklists.com' + setLink.find('a').get('href')\n",
    "        print(i, link)\n",
    "        \n",
    "        if grep and (grep not in link):\n",
    "            if verbose:\n",
    "                print(\"ignoring: %s\", (link))\n",
    "            continue\n",
    "            \n",
    "        #print(link)\n",
    "        if start and (i<start):\n",
    "            continue\n",
    "        \n",
    "        urls.append(link)\n",
    "        if limit and (i > limit):\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    print(urls)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    return urls\n",
    "\n",
    "def dump_list(l):\n",
    "    print(*[\"%s\\n\" % (i) for i in l ])\n",
    "        \n",
    "        \n",
    "def get_one_set(url, debug=False, detect_problem=True):\n",
    "\n",
    "    soup = get_html(url)\n",
    "    \n",
    "    i = 1\n",
    "    for a in soup.find_all('tr'): #, id=\"tlp_3943296\"):\n",
    "        names=[]\n",
    "        cues=[]\n",
    "        #print(a)\n",
    "\n",
    "        for name in a.find_all('div', {\"class\": \"tlToogleData\"}):\n",
    "            name = name.text.strip()\n",
    "            #print(name)\n",
    "            if \"\\n\" in name:\n",
    "                name = name.splitlines()[0]\n",
    "\n",
    "            if \"correct label is\" in name:\n",
    "                continue\n",
    "\n",
    "            names.append(name)\n",
    "\n",
    "        for cue in a.find_all('div', {\"class\": \"cueValueField\"}):\n",
    "            cue = cue.text.strip()\n",
    "            cues.append(cue)\n",
    "\n",
    "        if names == []:\n",
    "            continue\n",
    "\n",
    "        i = i + 1\n",
    "        #print(names)\n",
    "        #print(cues)\n",
    "\n",
    "        name = \" \".join(names)\n",
    "        if cues == []:\n",
    "            cue = \"\"\n",
    "        else:\n",
    "            cue = \" \".join(cues)\n",
    "            cue = \"%s - \" % (cue)\n",
    "\n",
    "        line = \"%s%s\" % (cue, name)\n",
    "        print(line)\n",
    "        \n",
    "    if detect_problem and i <= 4:\n",
    "        raise Exception\n",
    "            \n",
    "        \n",
    "def do_work(data, limit=5, start=None, grep=None, token=None, oper=None):\n",
    "    \"\"\"\n",
    "    what:\n",
    "        index_sets:       single URL with a list -> get individual set urls\n",
    "        recursive_sets:   single URL with a list -> all sets details\n",
    "        isolated_sets:    input is a LIST of urls -> get set details\n",
    "    \n",
    "    \"\"\"\n",
    "    if token != 1:\n",
    "        print(\"ERROR: Bad token\")\n",
    "        return\n",
    "\n",
    "    ###\n",
    "    for line in data.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        if oper == \"index_sets\":\n",
    "            get_latest_urls(line, limit=limit, start=start)\n",
    "\n",
    "        elif oper == \"recursive_sets\":\n",
    "            get_recursive_sets(line, limit=limit, start=start, grep=grep)\n",
    "\n",
    "        elif oper == \"isolated_sets\":\n",
    "            get_one_set(line)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown value\", what)\n",
    "\n",
    "\n",
    "##########\n",
    "##########\n",
    "\n",
    "#https://www.1001tracklists.com/source/4j7q4v/luminosity-beach-festival/index2.html\n",
    "    \n",
    "    \n",
    "data=\"\"\"\n",
    "\n",
    "https://www.1001tracklists.com/source/4j7q4v/luminosity-beach-festival/index.html\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "token=2\n",
    "\n",
    "start=None\n",
    "limit=None\n",
    "grep=None\n",
    "\n",
    "oper=\"index_sets\"\n",
    "#oper=\"recursive_sets\"\n",
    "#oper=\"isolated_sets\"\n",
    "#oper=None\n",
    "\n",
    "do_work(data, limit=limit, start=start, grep=grep, token=token, oper=oper)\n",
    "\n",
    "print('\\n\\nALL DONE \\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
